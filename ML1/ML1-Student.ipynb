{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML1 : Machine Learning with Pokemon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop we will go through the ML engineering process with a real dataset. We will be implementing each of the machine learning models that we discussed in ML0 and evaluate their performances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Our Data\n",
    "We will be looking at a pokemon data meant to resemble a pokedex. It's not update to take into account the most recent pokemon but had data for 800 different ones.\n",
    "\n",
    "#### Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning\n",
    "First lets look at our data by taking a sample of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first column in not needed so we will get rid of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This data has already been preprocessed before us, so we don't have much to do here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis\n",
    "\n",
    "Now that we have clean data lets do some EDA before we get into the ML\n",
    "\n",
    "#### Importing Seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Setting style preferences for seabron\n",
    "sns.set(style = 'darkgrid', color_codes = True)\n",
    "\n",
    "def setplt(x = 13, y = 9, a = 1, b = 1):\n",
    "    f, ax = plt.subplots(a,b,figsize = (x,y))\n",
    "    sns.despine(f, left = True, bottom = True)\n",
    "    return f, ax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make scatterplots comparing all the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above we can see that we can see clear distinctions in the rank when related to the other features. We can try to see if these features have any effect on other classes like discipline and sex and see that there is no relation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our Objective\n",
    "\n",
    "Our goal for this workshop is to come up with the most efficient model to predict the rank e.i. Associate Professor, Assistant Professor, or Professor (tenured). We are given the stats for each professor such as the years they have worked, salary, and the years they have had thier PhD.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Preparing our Data\n",
    "\n",
    "We now have to prepare out features and labels. We will also then have to create our training and testings sets. But first we need to replace some of the features with numerical values since out ML models will not take in strings. For example our disciple feature.\n",
    "\n",
    "<br>\n",
    "\n",
    "####  Encoding Labels\n",
    "ML models can't take in string values so they mush be converted to numerical values<br>\n",
    "<br>\n",
    "We needs to map the two types columns together so that similar types across columns won't have different labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating our Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating our Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-Test-Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the test-train-split function from sklearn.preprocessing\n",
    "\n",
    "\n",
    "print('Shape of training features : \\t' + str(X_train.shape))\n",
    "print('Shape of training labels : \\t' + str(y_train.shape))\n",
    "print('Shape of testing features : \\t' + str(X_test.shape))\n",
    "print('Shape of testing labels : \\t' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Finding the Best Model\n",
    "\n",
    "Now we will go through the ML models we discussed in ML0. We will create a classifier using each of these algorithms and evaluate them to see which one gives us the best performance. <br>\n",
    "<br>- K-Nearest-Neighbors\n",
    "<br>- Random Forest\n",
    "<br>- Support Vector Machine\n",
    "<br>- Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest-Neighbors Classification\n",
    "\n",
    "First we will try the KNN algorithm to create a KNN Classifier\n",
    "<br><br>\n",
    "Documentation:\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html#sklearn.neighbors.KNeighborsClassifier.kneighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Classifier from Sci-Kit Learn\n",
    "\n",
    "# Initializing the KNN Classifier\n",
    " \n",
    "# Training model\n",
    "\n",
    "# Evaluating Method\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to find the value for n_neighbors to get us the best accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classification\n",
    "\n",
    "Now that we have an accuracy for our KNN model lets try and see if we can get better performance with out RF algorithm since 0.775 is not considered to be very accurate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import RF Classifier\n",
    "\n",
    "# Initialize the Random Forest\n",
    "        # Using Gini index to measure feature importance \n",
    "\n",
    "# Train Model\n",
    "\n",
    "# Test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning Parameters\n",
    "\n",
    "Here we will have to tune our n_estimators parameter. There are others such as the criterion (above), bootstrapping, max_features, etc... For this our case we can simply use the default values that sklearn RFC gives us, and will mainly worry about the number of trees. Hence, we will tune the parameters similar to the way we did with KNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE : </b> Since the creating of the model is randomized and not uniform like KNN, there will be a different testing accuracy every time because different bootstraps are being used to create our random forest every time we train. If you keep running the block above, the accuracy will be constantly changing.\n",
    "\n",
    "\n",
    "#### Why did the RFC do better?\n",
    "Our RFC model did pretty well compared to the KNN model. This is because this data can be easily categorized. Notice in the pairplots we made above the data can be seperated visually but there is a lot of overlap between the classes. Because of this KNN might have worse performance towards the edges. Random Forest allows us to make more reasonable distinctions using feature values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine Classification\n",
    "\n",
    "Now we will try to use the SVC algorithm to create a classification model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing SVC\n",
    "\n",
    "# Initialize the SVC\n",
    "\n",
    "# Train Model\n",
    "\n",
    "# Test Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Tuning Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case we want to find the best combination of parameters since we will be chaning more than one paramter. Lets define the ones we want to change. Since we are working with the RBF kernel (we have more than three features so this is optimal) we will have to optimize the C and gamma parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sci-Kit Learn has a very useful tool called the GridSearch. This makes finding the best paramters more simple but it essentially still uses trial and error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing GridSearch\n",
    "\n",
    "# Initialize the GridSearch \n",
    "\n",
    "# Try all combinations\n",
    "\n",
    "# Observe best parameters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>NOTE : </b> Grid search can be used to optimize any of the classical machine learning models we have discussed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multi-Layer Perceptron\n",
    "We will now attempt to use a neural network to create a deep learning model. We will be using the keras library built from tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Design\n",
    "\n",
    "First we will need to design our MLP given the features we have and what we need from the output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sizes of vital layers\n",
    "\n",
    "<b>Input Layer : </b> The number of features we are training on so in this case it will be <code>len(features.columns ) = 5</code>\n",
    "<br>\n",
    "<b>Hidden Layer : </b> We will experiment with the hidden layers but for now will just include the 4 nodes in a single hidden layer <br>\n",
    "<b>Output Layer : </b> The amount of unique labels we will classify data points as <code>len(targets.unique()) = 3</code>\n",
    "<br><br>\n",
    "<img src='nn.png' width='550'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the architecture lets implement our network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential                       # Feed-Forward Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation       # Layers and Activation Functions\n",
    "from tensorflow.keras.optimizers import SGD                          # Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Encoding the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# FOR ONE-HOT ENCODING (not used for now)\n",
    "\n",
    "# Legendary = [1,0]\n",
    "# Not-Legendary = [0,1]\n",
    "\n",
    "# onehotencoder = OneHotEncoder(sparse = False)\n",
    "# y_train = y_train.reshape(len(y_train),1)\n",
    "# y_test = y_test.reshape(len(y_test),1)\n",
    "# y_train = onehotencoder.fit_transform(y_train).astype(int)\n",
    "# y_test = onehotencoder.fit_transform(y_test).astype(int)\n",
    "# y_train[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Initializing the MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Performance\n",
    "\n",
    "Notice how the Neural Network did not perform as well as the other models. This is mainly because MLP's are best when used with data that has a lot of features. For data with a low number of features a simpler method like RF will work better."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You\n",
    "\n",
    "Thanks for attending our first run of the ML series. Let us know if you enjoyed it or what you think could be improved, we are always looking information on how to improve our workshops to work better in the future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interested in DSI?\n",
    "\n",
    "We are currently looking for new members to serve on our Junior Executive Board. If you are interested please come up and talk to us so we can giev you imformation about the application and interview process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
