{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML0 : An Introduction to Machine Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this workshop we will cover the basics of machine learning. We will discuss the basic princples of machine learning and how to properly clean and format data in order to implement these models. This workshop will go over some ML models but mainly the theory behind them. Implementations will be discussed ML1. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is Machine Learning?\n",
    "\n",
    "Machine Learning is a subset of Artificial Intelligence that relies on the idea that machines and learn from data. It invokes a process that is used to identify different patterns in given data and make decisions without human intervention. Machine Learning has a number of applications in the field of data science including image processing, classification, language processing, and learning association. \n",
    "\n",
    "<img src=\"AI-Intro.png\" width='600'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How it Works | A short blurb\n",
    "It all essentially starts with the data. We feed data into a machine learning algorithm of our choosing (or creation) in order to train it. During training, the model will essentially start to recognize patterns from the data it is given and then is able to make the decisions you have designed it to make. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Process\n",
    "We will now give an overview of each step in the machine learning model creation process. While these steps are not always set in stone it is the steps one takes as an ML engineer to carry out their work efficiently without too many hiccups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview\n",
    "    1. Data Cleaning and Formatting\n",
    "    2. Exploratory Data Analysis (EDA)\n",
    "    3. Design/Choose Model\n",
    "    4. Create Training and Testing Data\n",
    "    5. Train Model\n",
    "    6. Test Model\n",
    "    7. Tune Hyperparamters\n",
    "    8. Repeat steps 6-8 until good testing accuracy (or other testing metric) is reached\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1 : Data Cleaning and Formatting\n",
    "The first step will always be data cleaning. One of the problems with machine learning is that the data fed into the models should be pristine. Most models will result in errors if there is something wrong with data types or formatting. A good idea is to outline how you want your data to be formatted and then clean the data you get to those specifications.\n",
    "\n",
    "### Step 2 : Exporatory Data Analysis \n",
    "Once your data is clean, spend some time analyzing what you have. Look to see if you can decipher some patterns and relationships yourself. Use visualizations to aid in this process. Try to make statistical observations. For example: contructing linear models to determine relationships between different features. Regression is after all a subset of Machine Learning. EDA is extrmemely important in because first you have to be able to detmine a purpose for you model before you design one. In order to do this you have to know your data well.\n",
    "\n",
    "### Step 3 : Design/Choose\n",
    "After you have a plan of what purpose you want your ML model to serve, you then have to choose/implement the model. This is a tricky process as there is a lot that goes into this step.\n",
    "#### Step 3.1 : Three Main Branches of Machine Learning\n",
    "Before we start choosing a model to use, we have to first find out what type of problem we are solving. Almost all problems will fall under one of the three categories of machine learning:\n",
    "##### - Supervised Learning\n",
    "The goal of supervised learning to determine a function. As a review of the basics, functions have inputs and outputs. Supervised learning uses data to come up with a function that fits the data. That way a prediction can be made when the model is introducted to a new data point. This type of machine learning requires that the data have inputs and sample outputs for each data point to use to train the model. This is the most popular method of learning used by data scientists to implement in the field.\n",
    "##### - Unsupervised Learning\n",
    "The goal of unsupervised learning is determine hidden patterns in the data from unlabeled data (data with just input points and no outputs). Its is mainly used for processes like anomaly detection ot data pre-processing. It is also used to sometimes pre-train data and provide outputs values that can then be used in supervised learning models (semi-supervised learning) \n",
    "##### - Reinforcement Learning\n",
    "This method trains machine learning models to make make series of decisions. It uses trial and terror to come up with solutions to problems and react to the environment they run in. Although not used a lot in mainstream industry there are still a lot of application such as in Game AI.<br><br>\n",
    "<img src='branches_ml.png' width='600' align='center'/>\n",
    "\n",
    "#### Step 3.2 : Data - Features and Targets\n",
    "The data we use in ML can split into features and targets. While mostly used in supervised learning it is key to training most ML models. Features are all the data collected for each data point and the target is what you want to be able to predict about each data point.<br><br> For example: If we want to make a machine learning model that can determine whether or not a pokemon is legendary, we would have data such as the following: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>Slowking</td>\n",
       "      <td>Water</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>490</td>\n",
       "      <td>95</td>\n",
       "      <td>75</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>110</td>\n",
       "      <td>30</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>Magmortar</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>540</td>\n",
       "      <td>75</td>\n",
       "      <td>95</td>\n",
       "      <td>67</td>\n",
       "      <td>125</td>\n",
       "      <td>95</td>\n",
       "      <td>83</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>Magby</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>365</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>37</td>\n",
       "      <td>70</td>\n",
       "      <td>55</td>\n",
       "      <td>83</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>581</th>\n",
       "      <td>Blitzle</td>\n",
       "      <td>Electric</td>\n",
       "      <td>NaN</td>\n",
       "      <td>295</td>\n",
       "      <td>45</td>\n",
       "      <td>60</td>\n",
       "      <td>32</td>\n",
       "      <td>50</td>\n",
       "      <td>32</td>\n",
       "      <td>76</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>Politoed</td>\n",
       "      <td>Water</td>\n",
       "      <td>NaN</td>\n",
       "      <td>500</td>\n",
       "      <td>90</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>90</td>\n",
       "      <td>100</td>\n",
       "      <td>70</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Name    Type 1   Type 2  Total  HP  Attack  Defense  Sp. Atk  \\\n",
       "214   Slowking     Water  Psychic    490  95      75       80      100   \n",
       "518  Magmortar      Fire      NaN    540  75      95       67      125   \n",
       "259      Magby      Fire      NaN    365  45      75       37       70   \n",
       "581    Blitzle  Electric      NaN    295  45      60       32       50   \n",
       "201   Politoed     Water      NaN    500  90      75       75       90   \n",
       "\n",
       "     Sp. Def  Speed  Generation  Legendary  \n",
       "214      110     30           2      False  \n",
       "518       95     83           4      False  \n",
       "259       55     83           2      False  \n",
       "581       32     76           5      False  \n",
       "201      100     70           2      False  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "\n",
    "data = read_csv('pokemon.csv')\n",
    "data = data.drop(columns=['#'])\n",
    "data.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above data, each row would represent a data point. The features would be all the columns that represent the data point such as HP, Attack, Defense, etc. The target would be the column we are trying to predict, in this case the legendary column. Once completed the ML model will be able to take the above features (without the legendary column) and be able to predict, a degree of accuracy, whether or not the pokemon is Legendary or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = data.drop(columns=['Legendary'])\n",
    "targets = data.Legendary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>Total</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>318</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>405</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Name Type 1  Type 2  Total  HP  Attack  Defense  Sp. Atk  Sp. Def  \\\n",
       "0  Bulbasaur  Grass  Poison    318  45      49       49       65       65   \n",
       "1    Ivysaur  Grass  Poison    405  60      62       63       80       80   \n",
       "\n",
       "   Speed  Generation  \n",
       "0     45           1  \n",
       "1     60           1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    False\n",
       "1    False\n",
       "Name: Legendary, dtype: bool"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is how you would split the data into its features and targets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3.3 : Choosing the Model\n",
    "Now what we understand out what our objective is, we can choose a model. It is important to choose the model you want based on your objective, but it is not essential as it is always good to try different models to check to see if the one you have chosen does in fact have the best performance. We will briefly go over some basic models but will be implementing them in the next workshop ML1\n",
    "\n",
    "##### - K-Nearest-Neighbors\n",
    "The KNN Algorithm is a pretty naive but effective algorithm. It works well when all the features have numerical values and there are a low number of features (curse of dimensionality). For training all it does is plot the points in n-dimensional space where <code>n = len(features)</code> and labels them with their correspoding target values. The user then selects a k value. K is the KNN hyperparameter that needs to be tunes by you. For classification it plots the new data point and then looks for the k closest data points. It then looks at all the labels for each and determines the one that occurs the most. It then classifies the new point as that label.\n",
    "    \n",
    "<img src='Knn-Alg.jpg' width='400'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand how RF Models work, we need to understand the concept of a decision tree. \n",
    "<br><br>\n",
    "<b>Decision Tree:</b>\n",
    "As the name suggests, a decision tree uses a tree-like model to make decisions. In machine learning they are used to allow models to represent decisions and decision making. Data can be converted into a decision tree where the features and thier values decided where the branches are and leaves would be the result or the targets. Here is an example of a decision tree that uses data from features to predict how many bedrooms their house has:\n",
    "<br><img src='DecisionTree.png' width='600'><br>\n",
    "In this case the # of family members, the household income, and the marital status are all items in the feature set while the flat size would be the target values. The data used to construc that tree would look something like this: \n",
    "<br><br><img src='DTData.png'>\n",
    "<br><br>\n",
    "A <b>random forest</b> is basically a collection of these decision trees ( get it lol ) that are constructed by bootstrapping the data. Bootstrapping is subestting the data without any restriction on length many different time. Data points also arent restricted in how many time they can be used in a subset. During training a random forest will create n decision trees using different random subset each time. N is a hyperparameter selected by the user. For classification a data point will enter the top of each tree and the results of all the trees will be tallied. The label given to the new data point will be the majority of the results obtained as shown below:\n",
    "\n",
    "<br><img src='Random-Forest-Introduction.png' width = '500'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Support Vector Machines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similar to KNN, the SVM model starts off by plotting all the points from the feature set and labeling them. This is also referred to as the feature space. Instead of looking at neighbors, the goal of SVM is to determine a hyperplane (or line in 2D) that can seperate out all the target classifications. For classification it plots a new data point where it falls into one of these seperated regions labeling the new data point based on that. Here is an example of this being done in 2D (2 features).\n",
    "\n",
    "<br><img src='SVMLinear.png'>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more complicated scenario such as the one below can be tackled using a method called the <b>kernel trick</b>.\n",
    "\n",
    "<br><img src='KernelTrick.png'><br>\n",
    "This is when we can transform the orignal data to be able to easily draw a hyperplane. Then the data and hyperplace is transformed back. Notice how in the below figure to the left, the data is all moved above the x-axis, probably the taking the absolute value of them. Then a line can easily be drawn through. Its is then transformed with the new hyperplane."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td><img src='KernelTrickTransformed.png'></td>\n",
    "<td><img src='KernelTrickFinal.png'></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Overfitting:</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is important to keep in mind fitting a hyperplane too well to a set of training data may not be the best thing. Look at the following images. Which representation do you think is better?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<tr>\n",
    "<td><img src='Overfit1.png'></td>\n",
    "<td><img src='Overfit2.png'></td>\n",
    "</tr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would actually be the first one on the left. Even though it does't take into account for two of the points it would probably perform better. The one on the right is an example of overfitting the model to the training data. This is bad because the model can get so used to the training data than when introduce testing or real-world data there is a high chance for misclassification. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### - Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks are one of the most popular models used in Machine Learning and in Deep Learning. They are meant to imitate the way we think, and are designed after the neurons in our brain. The way we learn is through a series of observations (features?) and eventually after enought observeations we can determine facts (labels?). While we are learning we process these observations, looking at different scenarious in a method similar to trial and error in order to figure out what the final fact is. Neural networks work the same way. <br><br> This is the general structure of a deep neural network:\n",
    "<br>\n",
    "\n",
    "<img src='MLP.png' width='500'><br>\n",
    "\n",
    "<br>\n",
    "<b>Overview:</b>\n",
    "An observation (feature) is put in through the input layer. At each layer the nodes have a different activation function which is applied to the values from the previous layer. (Note: This is similar to neurons firing at thier synapses before passing them onto the next neuron) Before reaching each node (flowing though the neuron) the values are weighted. During training, the input flows through the network being weighted and activated at each layer before finally getting a predicted output. After going through the network, the model evaluates the output and compare it with the target value. It then backpropogrates though the network and changes the weights in hopes that it will now reach the right target value.\n",
    "<br><br>\n",
    "<img src='Backprop.png' width='700'>\n",
    "<br>\n",
    "<b>Channels and Weights:</b> Connecting each layer (node to node) are channels. There is a channel with a weight connecting each node from the previous layer to each node in the next layer. The inputs from the previous layer are all multiplied by their corresponding weights. All the values are summed up from the channels and passed onto the nodes they are connected to. \n",
    "<br><br>\n",
    "<b>Bias:</b> After recieving a value, a bias is added to it\n",
    "<br><br>\n",
    "<b>Activation Function:</b> This is a threshold function that determines which neurons will be fired (continue to pass on their values) based on the value it holds.\n",
    "<br><br>\n",
    "<b>Backpropagation:</b> This is the process of going back through the network and changing the weights between layers. That way when the new data is fed though the network, it will be closer to reaching the desired output. The weights changed are determined from the <b>error</b> which is how far off the output was from the target.\n",
    "<br><br>\n",
    "<b>Batch Size:</b> The back size is the amount of data points that are fed through the network before backpropogation happens. This allows the model to collect enough data about the models performance so that it can adjust the weight accordingly.\n",
    "<br><br>\n",
    "<b> Cost Function & Opimization:</b> Before backpropogation starts, the model needs to know how to change the weights. The way it does this is by creating a function from the error collected from the batch. It then optimizes the error by minimizing the loss function.\n",
    "<br><br>\n",
    "<b>Epoch:</b> An epoch is when all the data is put thought the suring training and the weights have been adjusted accordingly. Even though by the end of epoch, the all the data has been used, it will take mulitple epochs in order to fully train the model with good accuracy. In each epoch, the whole process including backpropogation after each batch is repeated.\n",
    "<br><br>\n",
    "<b>Hyperparameters:</b> Almost everything in the neural network is controlled by you. The design, including the size of each layer and the number of layers, the activation function being used, the optimization function and the format of your output are all in your hands.\n",
    "<br><br>\n",
    "<b>Example Video:</b> https://www.youtube.com/watch?v=bfmFfD2RIcg\n",
    "<br><br>\n",
    "<b>NOTE:</b> There is a lot more to neural networks but this is the basics of how they function. There are hundreds of different types and use cases for them but to go over all of them is beyond the scope of any one person."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4 : Creating Training and Testing Data\n",
    "\n",
    "Data can sometimes be hard to get or expensive. The data you have is all you can get so you need to be able to with what you get. When training a model, you can't use all your data otherwise you have no way to evaluate your model without getting more data. One method you can use is called train-test-split. <br><br>Let's try to do this on out pokemon data. We previously split the data into features and targets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features :(800, 11)\n",
      "Shape of targets :(800,)\n"
     ]
    }
   ],
   "source": [
    "X = features\n",
    "y = targets\n",
    "\n",
    "# Notice the dimensions of each\n",
    "print('Shape of features :' + str(X.shape))\n",
    "print('Shape of targets :' + str(y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training features :(536, 11)\n",
      "Shape of training targets :(536,)\n",
      "Shape of testing features :(264, 11)\n",
      "Shape of testing targets :(264,)\n"
     ]
    }
   ],
   "source": [
    "# Using sklearn implementation of train-test-split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)\n",
    "\n",
    "# Notice the dimensions of each\n",
    "print('Shape of training features :' + str(X_train.shape))\n",
    "print('Shape of training targets :' + str(y_train.shape))\n",
    "print('Shape of testing features :' + str(X_test.shape))\n",
    "print('Shape of testing targets :' + str(y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train the models using the training set and evaluate the model we train using the testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5 : Training Model\n",
    "\n",
    "The next will be training the data. We feed the training data we created into the model. Normally it's as simple as using .fit function built into most ML models. For example: <code>model.fit(X_train, y_train)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 6 : Testing Model\n",
    "\n",
    "Now that we have trained a model we have to test it using our testing data. Feed the testing data into the model so it will be evaluted <code>model.evaluate(X_test, y_test)</code> this will normally output an accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 7 : Tuning Hyperparameters\n",
    "\n",
    "Normally when creating a model for the first time, it won't have the best accuracy you can get. After testing you might have to change up your hyperparameters in order to get a better testing accuracy. Here are the hyperparamters for the models we discussed.\n",
    "<br><br>\n",
    "<b>KNN:</b>\n",
    "<br>\n",
    "<code>class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None)</code>\n",
    "<br><br>\n",
    "<b>Random Forest:</b>\n",
    "<br><br>\n",
    "<b>Classification</b><br> <code>class sklearn.neighbors.KNeighborsClassifier(n_neighbors=5, weights=’uniform’, algorithm=’auto’, leaf_size=30, p=2, metric=’minkowski’, metric_params=None, n_jobs=None)</code>\n",
    "<br><br>\n",
    "<b>Regression</b><br> <code>class sklearn.ensemble.RandomForestRegressor(n_estimators=’warn’, criterion=’mse’, max_depth=None, min_samples_split=2, min_samples_leaf=1, min_weight_fraction_leaf=0.0, max_features=’auto’, max_leaf_nodes=None, min_impurity_decrease=0.0, min_impurity_split=None, bootstrap=True, oob_score=False, n_jobs=None, random_state=None, verbose=0, warm_start=False)</code>\n",
    "<br><br>\n",
    "<b>SVM:</b>\n",
    "<br>\n",
    "<code>class sklearn.svm.SVC(C=1.0, kernel=’rbf’, degree=3, gamma=’auto_deprecated’, coef0=0.0, shrinking=True, probability=False, tol=0.001, cache_size=200, class_weight=None, verbose=False, max_iter=-1, decision_function_shape=’ovr’, random_state=None)</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 8 : Repeat\n",
    "\n",
    "We continue repeating steps 5-7 in order to find the perfect model that will complete the task you want it to be. A lot of the ML process is trial and error and it could take a long time to find one you are content with. So have patience! Eventually it will work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thank You\n",
    "\n",
    "Thanks for attending the first half of the ML workshop presented by DSI. I look forward to seeing everyone at ML1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
